{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c06c966-df09-47fd-8045-f1cedf31d89b",
   "metadata": {},
   "source": [
    "# **Agnes Hephzibah Roche CM3015 Mid-term coursework**\n",
    "## **Abstract**\n",
    "In this project, we analyse and compare the performance of different machine learning algorithms on the Breast Cancer dataset from scikit-learn. The dataset consists of 569 samples with 30 features, representing real-world measurements related to cell nuclei from breast cancer images, classified into malignant or benign tumors. We implement k-Nearest Neighbors (kNN) and Naive Bayes algorithms from scratch and use scikit-learn to apply Logistic Regression and Decision Tree classifiers. Through cross-validation and hyperparameter tuning, we evaluate each model's effectiveness using metrics like accuracy, precision, recall, and F1 score to determine the best algorithm for breast cancer diagnosis.\n",
    "## **Introduction**\n",
    "In todayâ€™s world, machine learning plays a crucial role in making sense of complex data and helping with important tasks like medical diagnosis. This project focuses on using machine learning to analyze the Breast Cancer dataset from scikit-learn, which contains detailed measurements from tumor samples that are categorized as either malignant (cancerous) or benign (non-cancerous). The main goal of this project is to identify the best algorithm for accurately classifying these tumors by comparing different models. We will implement two algorithms, k-Nearest Neighbors (kNN) and Naive Bayes, from scratch to understand how they work under the hood, while also using scikit-learn to test Logistic Regression and Decision Tree models. By comparing these algorithms based on performance metrics, we aim to highlight their strengths and weaknesses and determine which model is most effective for breast cancer detection. This project not only demonstrates practical machine learning techniques but also showcases how these models can be applied to real-world healthcare challenges.\n",
    "## **Background**\n",
    "In this project, we utilize four key machine learning algorithms: k-Nearest Neighbors (kNN), Naive Bayes, Logistic Regression, and Decision Trees. Each of these algorithms has its own strengths and is suited for different types of classification problems.\r\n",
    "\r\n",
    "1. **k-Nearest Neighbors (kNN)**: kNN is a simple yet powerful algorithm used for classification tasks. It works by identifying the k closest data points (neighbors) to a given test point in the feature space and assigning the most common class among those neighbors. The distance between points is typically calculated using metrics like Euclidean distance. One of the advantages of kNN is its ability to adapt to the local structure of the data, making it effective for non-linear decision boundaries. However, it can be computationally expensive, especially with large datasets, as it requires calculating distances for each query point.\r\n",
    "\r\n",
    "2. **Naive Bayes**: Naive Bayes is a family of probabilistic algorithms based on applying Bayes' theorem, assuming that the features are conditionally independent given the class label. This assumption simplifies the computation of the posterior probabilities, making Naive Bayes efficient for large datasets. It works well for text classification and cases where the independence assumption approximately holds. Despite its simplicity, Naive Bayes often performs surprisingly well in practice, particularly for high-dimensional data.\r\n",
    "\r\n",
    "3. **Logistic Regression**: Logistic Regression is a statistical model used for binary classification tasks. It predicts the probability of a sample belonging to a particular class by modeling the relationship between the features and the log-odds of the outcome. The output is transformed using the logistic function, ensuring that predicted probabilities lie between 0 and 1. Logistic Regression is particularly effective for linearly separable data and is easy to interpret, making it a popular choice for binary classification problems in various fields, including healthcare.\r\n",
    "\r\n",
    "4. **Decision Trees**: Decision Trees are a versatile and interpretable model that can be used for both classification and regression tasks. They work by recursively splitting the dataset based on feature values to create a tree-like structure, where each internal node represents a decision based on a feature, and each leaf node represents a class label or value. Decision Trees can capture complex relationships in the data and handle both numerical and categorical features. However, they are prone to overfitting, especially when the tree is deep, but techniques like pruning and ensemble methods (e.g., Random Forests) can help mitigate this issue.\r\n",
    "\r\n",
    "By comparing these four algorithms, we can gain insights into their respective strengths and weaknesses in classifying breast cancer tumors, contributing to the development of more effective diagnostic tools in healthcare.s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dd4861-ef5d-42b8-b796-ff90eac4c21b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
